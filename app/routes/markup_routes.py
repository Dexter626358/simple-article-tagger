from __future__ import annotations

import json
import re
from pathlib import Path
from html import unescape

from flask import render_template_string, jsonify, request, abort, send_file

from app.app_dependencies import (
    METADATA_MARKUP_AVAILABLE,
    JSON_METADATA_AVAILABLE,
    extract_text_from_html,
    extract_text_from_pdf,
    load_json_metadata,
    save_json_metadata,
    form_data_to_json_structure,
    json_structure_to_form_data,
    find_docx_for_json,
)
from app.app_helpers import convert_file_to_html, merge_doi_url_in_html
from app.web_templates import VIEWER_TEMPLATE, MARKUP_TEMPLATE

def register_markup_routes(app, ctx):
    json_input_dir = ctx.get("json_input_dir")
    words_input_dir = ctx.get("words_input_dir")
    xml_output_dir = ctx.get("xml_output_dir")
    list_of_journals_path = ctx.get("list_of_journals_path")
    input_files_dir = ctx.get("input_files_dir")
    _input_files_dir = ctx.get("_input_files_dir")
    _words_input_dir = ctx.get("_words_input_dir")
    use_word_reader = ctx.get("use_word_reader")
    archive_root_dir = ctx.get("archive_root_dir")
    archive_retention_days = ctx.get("archive_retention_days")
    progress_state = ctx.get("progress_state")
    progress_lock = ctx.get("progress_lock")
    last_archive = ctx.get("last_archive")
    validate_zip_members = ctx.get("validate_zip_members")
    find_files_for_json = ctx.get("find_files_for_json")
    SUPPORTED_EXTENSIONS = ctx.get("SUPPORTED_EXTENSIONS")
    SUPPORTED_JSON_EXTENSIONS = ctx.get("SUPPORTED_JSON_EXTENSIONS")

    @app.route("/view/<path:filename>")
    def view_file(filename: str):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞."""
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø—É—Ç—å –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–ø–∞—Å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        if ".." in filename or filename.startswith("/") or filename.startswith("\\"):
            abort(404)
        
        base_dirs = [_input_files_dir, words_input_dir]
        file_path = None
        base_dir = None
        for candidate_base in base_dirs:
            if not candidate_base:
                continue
            candidate_path = candidate_base / filename
            if candidate_path.exists() and candidate_path.is_file():
                file_path = candidate_path
                base_dir = candidate_base
                break
        
        if not file_path:
            abort(404)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        if file_path.suffix.lower() not in SUPPORTED_EXTENSIONS:
            abort(404)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ words_input_dir
        try:
            file_path.resolve().relative_to(base_dir.resolve())
        except ValueError:
            abort(404)
        
        view_mode = (request.args.get("mode") or "html").lower()
        pdf_url = None
        if file_path.suffix.lower() == ".pdf":
            pdf_candidate = file_path
        else:
            pdf_candidate = file_path.with_suffix(".pdf")
            if not pdf_candidate.exists():
                pdf_candidate = None
                try:
                    rel_path = file_path.relative_to(words_input_dir)
                    candidate = (_input_files_dir / rel_path).with_suffix(".pdf")
                    if candidate.exists():
                        pdf_candidate = candidate
                except Exception:
                    pass
        if pdf_candidate and pdf_candidate.exists():
            try:
                rel_pdf = pdf_candidate.relative_to(_input_files_dir)
                rel_pdf_url = str(rel_pdf).replace("\\", "/")
                pdf_url = f"/pdf/{rel_pdf_url}"
            except Exception:
                pdf_url = None

        try:
            html_body, warnings = convert_file_to_html(file_path, use_word_reader=use_word_reader)
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è, –º–æ–∂–Ω–æ –∏—Ö –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            if warnings:
                print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –¥–ª—è {filename}: {warnings}")
            
            html_url = f"/view/{filename}"
            pdf_view_url = f"/view/{filename}?mode=pdf"
            return render_template_string(
                VIEWER_TEMPLATE,
                filename=filename,
                content=html_body,
                view_mode=view_mode,
                html_url=html_url,
                pdf_view_url=pdf_view_url,
                pdf_url=pdf_url,
            )
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞: {e}"
            print(error_msg)
            return error_msg, 500
    

    @app.route("/markup/<path:json_filename>")
    def markup_file(json_filename: str):
        """–°—Ç—Ä–∞–Ω–∏—Ü–∞ —Ä–∞–∑–º–µ—Ç–∫–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ JSON —Ñ–∞–π–ª–∞."""
        if not METADATA_MARKUP_AVAILABLE or not JSON_METADATA_AVAILABLE:
            return "–û—à–∏–±–∫–∞: –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–æ–¥—É–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã", 500
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø—É—Ç—å –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–ø–∞—Å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        if ".." in json_filename or json_filename.startswith("/") or json_filename.startswith("\\"):
            abort(404)
        
        json_path = json_input_dir / json_filename
        
        if not json_path.exists() or not json_path.is_file():
            abort(404)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        if json_path.suffix.lower() != ".json":
            abort(404)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ json_input_dir
        try:
            json_path.resolve().relative_to(json_input_dir.resolve())
        except ValueError:
            abort(404)
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π JSON
            json_data = load_json_metadata(json_path)
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º JSON –≤ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ–æ—Ä–º—ã
            form_data = json_structure_to_form_data(json_data)
            
            # –ù–∞—Ö–æ–¥–∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã –≤ input_files
            # –õ–æ–≥–∏–∫–∞: PDF –¥–ª—è GPT, Word –¥–ª—è HTML (–µ—Å–ª–∏ –µ—Å—Ç—å), –∏–Ω–∞—á–µ PDF –¥–ª—è HTML
            pdf_for_gpt, file_for_html = find_files_for_json(json_path, _input_files_dir, json_input_dir)
            
            if not file_for_html:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–¥–ø–∞–ø–∫—É –¥–ª—è –±–æ–ª–µ–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
                try:
                    relative_path = json_path.relative_to(json_input_dir)
                    if len(relative_path.parts) > 1:
                        subdir_name = relative_path.parts[0]
                        error_msg = (
                            f"??????: ?? ?????? ???? ??? {json_filename}<br><br>"
                            f"?????? ? ????? input_files/{subdir_name}/:<br>"
                            f"- {json_path.stem}.pdf / {json_path.stem}.docx / {json_path.stem}.rtf / {json_path.stem}.idml / {json_path.stem}.html / {json_path.stem}.tex<br><br>"
                            f"- full_issue.docx / full_issue.rtf / full_issue.html / full_issue.tex (–ø–æ–ª–Ω—ã–π –≤—ã–ø—É—Å–∫)<br><br>"
                            f"????????? ???? ?: input_files/{subdir_name}/"
                        )
                    else:
                        error_msg = f"–û—à–∏–±–∫–∞: –Ω–µ –Ω–∞–π–¥–µ–Ω —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª –¥–ª—è {json_filename}"
                except ValueError:
                    error_msg = f"–û—à–∏–±–∫–∞: –Ω–µ –Ω–∞–π–¥–µ–Ω —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª –¥–ª—è {json_filename}"
                return error_msg, 404
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –¥–ª—è HTML PDF –∏–ª–∏ Word
            is_pdf_for_html = file_for_html.suffix.lower() == ".pdf"
            is_common_file = file_for_html.stem != json_path.stem
            
            # –î–ª—è HTML: –∏—Å–ø–æ–ª—å–∑—É–µ–º Word —Ñ–∞–π–ª –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ PDF
            if is_pdf_for_html:
                # –î–ª—è PDF —Ñ–∞–π–ª–æ–≤ –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏
                pdf_path_for_html = file_for_html
                warnings = []
                html_body = ""
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ PDF –¥–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏
                lines = extract_text_from_pdf(pdf_path_for_html)
            else:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Mistral
                config = None
                try:
                    config_path = Path("config.json")
                    if config_path.exists():
                        with open(config_path, "r", encoding="utf-8") as f:
                            config = json.load(f)
                except Exception:
                    pass
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ Mistral –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
                use_mistral = False
                if config:
                    use_mistral = config.get("pdf_to_html", {}).get("use_mistral", False)
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Word —Ñ–∞–π–ª –≤ HTML
                html_body, warnings = convert_file_to_html(
                    file_for_html,
                    use_word_reader=use_word_reader,
                    use_mistral=use_mistral,
                    config=config
                )
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ HTML –¥–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏
                lines = extract_text_from_html(html_body)
                pdf_path_for_html = None

            for line in lines:
                if "text" in line:
                    line["text"] = unescape(str(line.get("text", "")))
            
            # –î–ª—è GPT –∏—Å–ø–æ–ª—å–∑—É–µ–º PDF —Ñ–∞–π–ª (–µ—Å–ª–∏ –µ—Å—Ç—å), –∏–Ω–∞—á–µ None
            pdf_path = None
            if pdf_for_gpt:
                try:
                    pdf_path = pdf_for_gpt.resolve().relative_to(_input_files_dir.resolve())
                except ValueError:
                    pdf_path = pdf_for_gpt
            
            # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –æ—Ç–ª–∞–¥–æ—á–Ω—ã–π –≤—ã–≤–æ–¥ (–º–æ–∂–Ω–æ –≤–∫–ª—é—á–∏—Ç—å —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è DEBUG_LITERATURE=1)
            import os
            if not is_pdf_for_html and os.getenv("DEBUG_LITERATURE") == "1" and ("–õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞" in html_body or "–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞" in html_body.lower()):
                lit_pos = html_body.lower().find("–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞")
                if lit_pos != -1:
                    debug_html = html_body[max(0, lit_pos-100):lit_pos+2000]
                    print("=" * 80)
                    print("DEBUG: HTML –≤–æ–∫—Ä—É–≥ —Å–ª–æ–≤–∞ '–õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞':")
                    print("=" * 80)
                    print(debug_html)
                    print("=" * 80)
                
                print("=" * 80)
                print(f"DEBUG: –í—Å–µ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ —Å—Ç—Ä–æ–∫: {len(lines)}")
                lit_lines = [line for line in lines if "–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞" in line.get("text", "").lower() or 
                             (line.get("text", "").strip() and 
                              re.match(r'^\d+\.', line.get("text", "").strip()))]
                print(f"DEBUG: –ù–∞–π–¥–µ–Ω–æ —Å—Ç—Ä–æ–∫, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–æ–π: {len(lit_lines)}")
                if lit_lines:
                    print("DEBUG: –ü—Ä–∏–º–µ—Ä—ã —Å—Ç—Ä–æ–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã:")
                    for i, line in enumerate(lit_lines[:5], 1):
                        print(f"  {i}. –°—Ç—Ä–æ–∫–∞ {line.get('line_number')}: {line.get('text', '')[:100]}...")
                print("=" * 80)
            
            if warnings:
                print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –¥–ª—è {json_filename}: {warnings}")
            
            # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ–±—â–∏–π —Ñ–∞–π–ª, –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –Ω–∞—á–∞–ª–æ —Å—Ç–∞—Ç—å–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –∏/–∏–ª–∏ —Ñ–∞–º–∏–ª–∏–∏ –∞–≤—Ç–æ—Ä–∞
            article_start_line = None
            if is_common_file:
                # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –∏–∑ JSON (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: RUS, –∑–∞—Ç–µ–º ENG)
                art_titles = json_data.get("artTitles", {})
                title_rus = str(art_titles.get("RUS", "")).strip()
                title_eng = str(art_titles.get("ENG", "")).strip()
                search_title = title_rus if title_rus else title_eng
                
                # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–º–∏–ª–∏—é –ø–µ—Ä–≤–æ–≥–æ –∞–≤—Ç–æ—Ä–∞ –∏–∑ JSON (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: RUS, –∑–∞—Ç–µ–º ENG)
                author_surname = None
                authors = json_data.get("authors", [])
                if authors and isinstance(authors, list) and len(authors) > 0:
                    first_author = authors[0]
                    if isinstance(first_author, dict):
                        individ_info = first_author.get("individInfo", {})
                        rus_info = individ_info.get("RUS", {})
                        eng_info = individ_info.get("ENG", {})
                        surname_rus = str(rus_info.get("surname", "")).strip()
                        surname_eng = str(eng_info.get("surname", "")).strip()
                        author_surname = surname_rus if surname_rus else surname_eng
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–ª–∏ —Ñ–∞–º–∏–ª–∏—é –∞–≤—Ç–æ—Ä–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
                search_terms = []
                if search_title:
                    search_terms.append(("title", search_title))
                if author_surname and len(author_surname) >= 2:
                    search_terms.append(("author", author_surname))
                
                if search_terms:
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω–µ—Ü —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è (–æ–≥–ª–∞–≤–ª–µ–Ω–∏—è)
                    # –ò—â–µ–º –º–∞—Ä–∫–µ—Ä—ã —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è: "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ", "–û–≥–ª–∞–≤–ª–µ–Ω–∏–µ", "Contents", "Table of Contents"
                    content_end_line = 0
                    content_markers = [
                        r'—Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ',
                        r'–æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ',
                        r'contents',
                        r'table of contents',
                        r'—Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ\s*$',
                        r'–æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ\s*$',
                    ]
                    
                    # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ –º–∞—Ä–∫–µ—Ä–∞ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è
                    for idx, line in enumerate(lines):
                        line_text = line.get("text", "").lower().strip()
                        for marker in content_markers:
                            if re.search(marker, line_text, re.IGNORECASE):
                                # –ù–∞–π–¥–µ–Ω–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ, –∑–∞–ø–æ–º–∏–Ω–∞–µ–º —Å—Ç—Ä–æ–∫—É
                                # –û–±—ã—á–Ω–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –∑–∞–Ω–∏–º–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω–∏—Ü, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—â–µ 20-30 —Å—Ç—Ä–æ–∫
                                content_end_line = idx + 30
                                break
                        if content_end_line > 0:
                            break
                    
                    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –º–∞—Ä–∫–µ—Ä—ã, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–≤—ã–µ 50 —Å—Ç—Ä–æ–∫ (–≥–¥–µ –æ–±—ã—á–Ω–æ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ)
                    if content_end_line == 0:
                        content_end_line = min(50, len(lines))
                    
                    print(f"–ü–æ–∏—Å–∫ —Å—Ç–∞—Ç—å–∏ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å–æ —Å—Ç—Ä–æ–∫–∏ {content_end_line + 1} (–ø—Ä–æ–ø—É—â–µ–Ω–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ)")
                    if search_title:
                        print(f"  –ò—â–µ–º –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é: '{search_title[:50]}...'")
                    if author_surname:
                        print(f"  –ò—â–µ–º –ø–æ —Ñ–∞–º–∏–ª–∏–∏ –∞–≤—Ç–æ—Ä–∞: '{author_surname}'")
                    
                    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ —á–∞—Å—Ç—å—é —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è
                    def is_content_line(line_text):
                        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ —á–∞—Å—Ç—å—é —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è"""
                        text = line_text.strip()
                        # –ò—Å–∫–ª—é—á–∞–µ–º –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏
                        if len(text) < 5:
                            return True
                        # –ò—Å–∫–ª—é—á–∞–µ–º —Å—Ç—Ä–æ–∫–∏, –∑–∞–∫–∞–Ω—á–∏–≤–∞—é—â–∏–µ—Å—è —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–º (–Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã)
                        if re.search(r'^\s*\S+.*\d+\s*$', text) and len(re.findall(r'\d+', text)) <= 2:
                            return True
                        return False
                    
                    # –ò—â–µ–º –ø–æ –≤—Å–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–º —Ç–µ—Ä–º–∏–Ω–∞–º (—Å–Ω–∞—á–∞–ª–∞ —Ñ–∞–º–∏–ª–∏—è –∞–≤—Ç–æ—Ä–∞, –∑–∞—Ç–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ)
                    # –§–∞–º–∏–ª–∏—è –∞–≤—Ç–æ—Ä–∞ –æ–±—ã—á–Ω–æ –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–π –º–∞—Ä–∫–µ—Ä
                    search_order = sorted(search_terms, key=lambda x: 0 if x[0] == "author" else 1)
                    
                    for search_type, search_term in search_order:
                        if article_start_line:
                            break
                        
                        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ—Ä–º–∏–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞
                        search_term_normalized = re.sub(r'\s+', ' ', search_term.lower().strip())
                        
                        # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∏–ª–∏ —á–∞—Å—Ç–∏—á–Ω–æ–µ
                        for idx in range(content_end_line, len(lines)):
                            line = lines[idx]
                            line_text = line.get("text", "")
                            line_text_normalized = re.sub(r'\s+', ' ', line_text.lower().strip())
                            
                            # –î–ª—è —Ñ–∞–º–∏–ª–∏–∏ –∞–≤—Ç–æ—Ä–∞ –∏—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∏–ª–∏ –Ω–∞—á–∞–ª–æ —Å—Ç—Ä–æ–∫–∏
                            if search_type == "author":
                                # –§–∞–º–∏–ª–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–ª–æ–≤–æ–º –∏–ª–∏ –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏
                                if (search_term_normalized == line_text_normalized or
                                    line_text_normalized.startswith(search_term_normalized + " ") or
                                    re.search(r'\b' + re.escape(search_term_normalized) + r'\b', line_text_normalized)):
                                    if not is_content_line(line_text):
                                        article_start_line = idx + 1
                                        print(f"‚úì –ù–∞–π–¥–µ–Ω–æ –Ω–∞—á–∞–ª–æ —Å—Ç–∞—Ç—å–∏ –ø–æ —Ñ–∞–º–∏–ª–∏–∏ –∞–≤—Ç–æ—Ä–∞ '{search_term[:30]}...' –Ω–∞ —Å—Ç—Ä–æ–∫–µ {article_start_line}")
                                        break
                            
                            # –î–ª—è –Ω–∞–∑–≤–∞–Ω–∏—è –∏—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∏–ª–∏ —á–∞—Å—Ç–∏—á–Ω–æ–µ (–º–∏–Ω–∏–º—É–º 10 —Å–∏–º–≤–æ–ª–æ–≤)
                            elif search_type == "title":
                                if (search_term_normalized == line_text_normalized or 
                                    (len(search_term_normalized) >= 10 and search_term_normalized in line_text_normalized)):
                                    if not is_content_line(line_text):
                                        article_start_line = idx + 1
                                        print(f"‚úì –ù–∞–π–¥–µ–Ω–æ –Ω–∞—á–∞–ª–æ —Å—Ç–∞—Ç—å–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é '{search_term[:50]}...' –Ω–∞ —Å—Ç—Ä–æ–∫–µ {article_start_line}")
                                        break
                        
                        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏—è, –∏—â–µ–º –ø–æ –ø–µ—Ä–≤—ã–º —Å–ª–æ–≤–∞–º
                        if not article_start_line and search_type == "title" and len(search_term.split()) >= 3:
                            title_words = search_term.split()
                            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 3-5 —Å–ª–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
                            search_phrase = " ".join(title_words[:min(5, len(title_words))])
                            search_phrase_normalized = re.sub(r'\s+', ' ', search_phrase.lower().strip())
                            
                            for idx in range(content_end_line, len(lines)):
                                line = lines[idx]
                                line_text = line.get("text", "")
                                line_text_normalized = re.sub(r'\s+', ' ', line_text.lower().strip())
                                
                                if search_phrase_normalized in line_text_normalized:
                                    if not is_content_line(line_text):
                                        article_start_line = idx + 1
                                        print(f"‚úì –ù–∞–π–¥–µ–Ω–æ –Ω–∞—á–∞–ª–æ —Å—Ç–∞—Ç—å–∏ –ø–æ –ø–µ—Ä–≤—ã–º —Å–ª–æ–≤–∞–º –Ω–∞–∑–≤–∞–Ω–∏—è '{search_phrase[:50]}...' –Ω–∞ —Å—Ç—Ä–æ–∫–µ {article_start_line}")
                                        break
            
            # –ü–µ—Ä–µ–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Ñ–æ—Ä–º—ã –≤ —à–∞–±–ª–æ–Ω –¥–ª—è –ø—Ä–µ–¥–∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–º, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–∏ –æ–±—â–∏–π —Ñ–∞–π–ª
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —á—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å:
            # - –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ PDF (is_pdf_for_html == True) ‚Üí –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ PDF viewer
            # - –ï—Å–ª–∏ –µ—Å—Ç—å Word —Ñ–∞–π–ª (is_pdf_for_html == False) ‚Üí –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ HTML (—Ç–µ–∫—Å—Ç–æ–≤—É—é –ø–∞–Ω–µ–ª—å)
            pdf_path_for_viewer = None
            if pdf_for_gpt:
                try:
                    pdf_relative = pdf_for_gpt.relative_to(_input_files_dir)
                    pdf_path_for_viewer = str(pdf_relative.as_posix())
                except ValueError:
                    pdf_path_for_viewer = pdf_for_gpt.name
            elif pdf_path_for_html:
                try:
                    pdf_relative = pdf_path_for_html.relative_to(_input_files_dir)
                    pdf_path_for_viewer = str(pdf_relative.as_posix())
                except ValueError:
                    pdf_path_for_viewer = pdf_path_for_html.name

            show_pdf_viewer = pdf_path_for_viewer is not None
            show_text_panel = True

            view_mode = (request.args.get("view") or "html").lower()
            if view_mode not in ("html", "pdf"):
                view_mode = "html"
            if view_mode == "pdf" and not show_pdf_viewer:
                view_mode = "html"

            print(f"DEBUG: is_pdf_for_html={is_pdf_for_html}, show_pdf_viewer={show_pdf_viewer}, show_text_panel={show_text_panel}, view_mode={view_mode}")

            return render_template_string(
                MARKUP_TEMPLATE, 
                filename=json_filename, 
                lines=lines,
                form_data=form_data or {},
                is_common_file=is_common_file,
                common_file_name=file_for_html.name if is_common_file else None,
                article_start_line=article_start_line,
                pdf_path=pdf_path_for_viewer,
                show_pdf_viewer=show_pdf_viewer,
                show_text_panel=show_text_panel,
                view_mode=view_mode
            )
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ —Ä–∞–∑–º–µ—Ç–∫–∏: {e}"
            print(error_msg)
            return error_msg, 500
    

    @app.route("/api/article/<path:json_filename>")
    def api_get_article(json_filename: str):
        """API endpoint –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ç—å–∏ —á–µ—Ä–µ–∑ AJAX."""
        # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –º–æ–¥—É–ª—å re
        global re
        if not METADATA_MARKUP_AVAILABLE or not JSON_METADATA_AVAILABLE:
            return jsonify(error="–ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–æ–¥—É–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã"), 500
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø—É—Ç—å –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–ø–∞—Å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        if ".." in json_filename or json_filename.startswith("/") or json_filename.startswith("\\"):
            abort(404)
        
        json_path = json_input_dir / json_filename
        
        if not json_path.exists() or not json_path.is_file():
            abort(404)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        if json_path.suffix.lower() != ".json":
            abort(404)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ json_input_dir
        try:
            json_path.resolve().relative_to(json_input_dir.resolve())
        except ValueError:
            abort(404)
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π JSON
            json_data = load_json_metadata(json_path)
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º JSON –≤ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ–æ—Ä–º—ã
            form_data = json_structure_to_form_data(json_data)
            
            # –ù–∞—Ö–æ–¥–∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π DOCX —Ñ–∞–π–ª
            pdf_for_gpt, file_for_html = find_files_for_json(json_path, _input_files_dir, json_input_dir)

            if not file_for_html:
                return jsonify(error="???? ?????? ?? ?????? ? input_files"), 404

            docx_path = file_for_html
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –æ–±—â–∏–º —Ñ–∞–π–ª–æ–º –≤—ã–ø—É—Å–∫–∞
            is_common_file = docx_path.stem != json_path.stem
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª PDF
            is_pdf = docx_path.suffix.lower() == ".pdf"
            
            if is_pdf:
                # –î–ª—è PDF —Ñ–∞–π–ª–æ–≤ –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏
                pdf_path = docx_path  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Ç—å –∫ PDF
                warnings = []  # –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π –¥–ª—è PDF
                html_body = ""  # –ü—É—Å—Ç–æ–µ —Ç–µ–ª–æ HTML –¥–ª—è PDF
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ PDF –¥–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏
                lines = extract_text_from_pdf(pdf_path)
            else:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Mistral
                config = None
                try:
                    config_path = Path("config.json")
                    if config_path.exists():
                        with open(config_path, "r", encoding="utf-8") as f:
                            config = json.load(f)
                except Exception:
                    pass
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ Mistral –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
                use_mistral = False
                if config:
                    use_mistral = config.get("pdf_to_html", {}).get("use_mistral", False)
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ñ–∞–π–ª (DOCX/RTF) –≤ HTML
                html_body, warnings = convert_file_to_html(
                    docx_path,
                    use_word_reader=use_word_reader,
                    use_mistral=use_mistral,
                    config=config
                )
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ HTML –¥–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏
                lines = extract_text_from_html(html_body)
                pdf_path = None
            
            for line in lines:
                if "text" in line:
                    line["text"] = unescape(str(line.get("text", "")))

            # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ–±—â–∏–π —Ñ–∞–π–ª, –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –Ω–∞—á–∞–ª–æ —Å—Ç–∞—Ç—å–∏
            article_start_line = None
            if is_common_file:
                art_titles = json_data.get("artTitles", {})
                title_rus = str(art_titles.get("RUS", "")).strip()
                title_eng = str(art_titles.get("ENG", "")).strip()
                search_title = title_rus if title_rus else title_eng
                
                author_surname = None
                authors = json_data.get("authors", [])
                if authors and isinstance(authors, list) and len(authors) > 0:
                    first_author = authors[0]
                    if isinstance(first_author, dict):
                        individ_info = first_author.get("individInfo", {})
                        rus_info = individ_info.get("RUS", {})
                        eng_info = individ_info.get("ENG", {})
                        surname_rus = str(rus_info.get("surname", "")).strip()
                        surname_eng = str(eng_info.get("surname", "")).strip()
                        author_surname = surname_rus if surname_rus else surname_eng
                
                search_terms = []
                if search_title:
                    search_terms.append(("title", search_title))
                if author_surname and len(author_surname) >= 2:
                    search_terms.append(("author", author_surname))
                
                if search_terms:
                    content_end_line = 0
                    content_markers = [
                        r'—Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ',
                        r'–æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ',
                        r'contents',
                        r'table of contents',
                    ]
                    
                    for idx, line in enumerate(lines):
                        line_text = line.get("text", "").lower().strip()
                        for marker in content_markers:
                            if re.search(marker, line_text, re.IGNORECASE):
                                content_end_line = idx + 30
                                break
                        if content_end_line > 0:
                            break
                    
                    if content_end_line == 0:
                        content_end_line = min(50, len(lines))
                    
                    def is_content_line(line_text):
                        text = line_text.strip()
                        if len(text) < 5:
                            return True
                        if re.search(r'^\s*\S+.*\d+\s*$', text) and len(re.findall(r'\d+', text)) <= 2:
                            return True
                        return False
                    
                    search_order = sorted(search_terms, key=lambda x: 0 if x[0] == "author" else 1)
                    
                    for search_type, search_term in search_order:
                        if article_start_line:
                            break
                        
                        search_term_normalized = re.sub(r'\s+', ' ', search_term.lower().strip())
                        
                        for idx in range(content_end_line, len(lines)):
                            line = lines[idx]
                            line_text = line.get("text", "")
                            line_text_normalized = re.sub(r'\s+', ' ', line_text.lower().strip())
                            
                            if search_type == "author":
                                if (search_term_normalized == line_text_normalized or
                                    line_text_normalized.startswith(search_term_normalized + " ") or
                                    re.search(r'\b' + re.escape(search_term_normalized) + r'\b', line_text_normalized)):
                                    if not is_content_line(line_text):
                                        article_start_line = idx + 1
                                        break
                            
                            elif search_type == "title":
                                if (search_term_normalized == line_text_normalized or 
                                    (len(search_term_normalized) >= 10 and search_term_normalized in line_text_normalized)):
                                    if not is_content_line(line_text):
                                        article_start_line = idx + 1
                                        break
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º HTML –¥–ª—è —Ç–µ–∫—Å—Ç–∞ —Å—Ç–∞—Ç—å–∏ (—Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è)
            from html import escape
            text_html = '<div class="search-box" style="margin-bottom: 15px; position: sticky; top: 0; background: white; padding: 10px 0; z-index: 100; border-bottom: 1px solid #e0e0e0;"><input type="text" id="searchInput" placeholder="üîç –ü–æ–∏—Å–∫ –≤ —Ç–µ–∫—Å—Ç–µ..." style="width: 100%; padding: 10px; border: 1px solid #ddd; border-radius: 4px; font-size: 14px;"></div><div id="textContent">'
            for line in lines:
                line_text = escape(str(line.get("text", "")))
                line_id = escape(str(line.get("id", "")))
                line_number = escape(str(line.get("line_number", "")))
                # –î–æ–±–∞–≤–ª—è–µ–º –∫–ª–∞—Å—Å –¥–ª—è –Ω–∞—á–∞–ª–∞ —Å—Ç–∞—Ç—å–∏, –µ—Å–ª–∏ —ç—Ç–æ –Ω—É–∂–Ω–∞—è —Å—Ç—Ä–æ–∫–∞
                start_class = ' article-start-marker' if article_start_line and line.get("line_number") == article_start_line else ''
                text_html += f'<div class="line{start_class}" data-id="{line_id}" data-line="{line_number}"><span class="line-number">{line_number}</span><span class="line-text">{line_text}</span><button class="line-copy-btn" data-action="open-copy" title="–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç">‚úèÔ∏è</button></div>'
            text_html += '</div>'
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º HTML –¥–ª—è —Ñ–æ—Ä–º—ã (–∏—Å–ø–æ–ª—å–∑—É–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é MARKUP_TEMPLATE)
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —Ñ–æ—Ä–º—É –∏–∑ MARKUP_TEMPLATE
            from jinja2 import Template
            form_template = Template(MARKUP_TEMPLATE)
            form_html = form_template.render(
                filename=json_filename,
                form_data=form_data,
                lines=lines,
                is_common_file=is_common_file,
                article_start_line=article_start_line,
                common_file_name=docx_path.name if is_common_file else None
            )
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —á–∞—Å—Ç—å —Ñ–æ—Ä–º—ã (–±–µ–∑ –≤—Å–µ–≥–æ —à–∞–±–ª–æ–Ω–∞)
            # –ù–∞—Ö–æ–¥–∏–º –Ω–∞—á–∞–ª–æ —Ñ–æ—Ä–º—ã
            form_start = form_html.find('<form id="metadataForm">')
            form_end = form_html.find('</form>') + 7
            
            if form_start != -1 and form_end > form_start:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–æ—Ä–º—É –∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
                instructions_start = form_html.find('<div class="instructions">')
                instructions_end = form_html.find('</div>', instructions_start) + 6 if instructions_start != -1 else -1
                
                form_section = ''
                if instructions_start != -1 and instructions_end > instructions_start:
                    form_section += form_html[instructions_start:instructions_end]
                form_section += form_html[form_start:form_end]
                
                # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞–Ω–µ–ª—å –≤—ã–±–æ—Ä–∞ –ø–æ–ª–µ–π
                selection_panel_start = form_html.find('<div id="selectionPanel"')
                if selection_panel_start != -1:
                    # –ù–∞—Ö–æ–¥–∏–º –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–π —Ç–µ–≥ –¥–ª—è selectionPanel (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤–ª–æ–∂–µ–Ω)
                    depth = 0
                    pos = selection_panel_start
                    selection_panel_end = len(form_html)
                    while pos < len(form_html):
                        if form_html[pos:pos+4] == '<div':
                            depth += 1
                        elif form_html[pos:pos+6] == '</div>':
                            depth -= 1
                            if depth == 0:
                                selection_panel_end = pos + 6
                                break
                        pos += 1
                    form_section += form_html[selection_panel_start:selection_panel_end]
                
                # –ù–ï –∏–∑–≤–ª–µ–∫–∞–µ–º JavaScript –∏–∑ MARKUP_TEMPLATE, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫
                # –í—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ —É–∂–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –≤ –≥–ª–∞–≤–Ω–æ–º —à–∞–±–ª–æ–Ω–µ HTML_TEMPLATE
                # JavaScript –∏–∑ MARKUP_TEMPLATE –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å–ª–æ–∂–Ω—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –ª–æ–º–∞—é—Ç—Å—è –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏
            else:
                form_section = '<p>–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–æ—Ä–º—ã</p>'
            
            return jsonify({
                "html_content": text_html,
                "form_html": form_section,
                "filename": json_filename,
                "article_start_line": article_start_line
            })
            
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç–∞—Ç—å–∏: {e}"
            print(error_msg)
            import traceback
            error_details = traceback.format_exc()
            print(error_details)
            return jsonify(error=error_msg, details=error_details), 500
    

    @app.route("/process-references-ai", methods=["POST"])
    def process_references_ai():
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã —Å –ø–æ–º–æ—â—å—é –ò–ò –ø—Ä—è–º–æ –≤ –≤–µ–±-—Ñ–æ—Ä–º–µ."""
        try:
            data = request.get_json()
            field_id = data.get("field_id")  # "references_ru" –∏–ª–∏ "references_en"
            raw_text = data.get("text", "")
            
            if not raw_text or not raw_text.strip():
                return jsonify(success=False, error="–¢–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—É—Å—Ç"), 400
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —è–∑—ã–∫ –∏ –≤—ã–±–∏—Ä–∞–µ–º –ø—Ä–æ–º–ø—Ç
            language = "RUS" if field_id == "references_ru" else "ENG"
            prompt_type = "references_formatting_rus" if language == "RUS" else "references_formatting_eng"
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            config = None
            try:
                config_path = Path("config.json")
                if config_path.exists():
                    with open(config_path, "r", encoding="utf-8") as f:
                        config = json.load(f)
            except Exception:
                pass
            
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–º–ø—Ç –∏–∑ prompts.py
            try:
                from prompts import Prompts
                base_prompt = Prompts.get_prompt(prompt_type)
                prompt = base_prompt.format(references_text=raw_text)
            except Exception as e:
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ–º–ø—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π
                lang_name = "–†—É—Å—Å–∫–∏–π" if language == "RUS" else "English"
                prompt = f"""–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö —Å–ø–∏—Å–∫–æ–≤ –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π.

–ó–∞–¥–∞—á–∞: –†–∞–∑–±–µ—Ä–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–ø–∏—Å–∫–∞ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã –∏ –≤–µ—Ä–Ω–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫, –≥–¥–µ –∫–∞–∂–¥–∞—è –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∞—è –∑–∞–ø–∏—Å—å –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–µ.

–ü—Ä–∞–≤–∏–ª–∞:
1. –£–±–µ—Ä–∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤–Ω—É—Ç—Ä–∏ —Å–ª–æ–≤, —Ñ–∞–º–∏–ª–∏–π, –∏–Ω–∏—Ü–∏–∞–ª–æ–≤
2. –û–±—ä–µ–¥–∏–Ω–∏ —Ä–∞–∑–æ—Ä–≤–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ (–µ—Å–ª–∏ –∞–≤—Ç–æ—Ä, –Ω–∞–∑–≤–∞–Ω–∏–µ, –≥–æ–¥, —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ä–∞–∑–±–∏—Ç—ã –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫)
3. –ò—Å–ø—Ä–∞–≤—å –ø–µ—Ä–µ–Ω–æ—Å—ã –≤–Ω—É—Ç—Ä–∏ —Å–ª–æ–≤
4. –°–æ—Ö—Ä–∞–Ω–∏ –≤—Å–µ –≤–∞–∂–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã: –∞–≤—Ç–æ—Ä—ã, –Ω–∞–∑–≤–∞–Ω–∏–µ, –≥–æ–¥, –∏–∑–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ, —Å—Ç—Ä–∞–Ω–∏—Ü—ã, DOI, URL
5. –ù–µ –æ–±—ä–µ–¥–∏–Ω—è–π —Ä–∞–∑–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –≤ –æ–¥–Ω—É –∑–∞–ø–∏—Å—å
6. –í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON: {{"references": ["–∑–∞–ø–∏—Å—å 1", "–∑–∞–ø–∏—Å—å 2", ...]}}

–Ø–∑—ã–∫: {lang_name}

–¢–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:
{raw_text}

–í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–π JSON –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤."""
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º GPT –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            from services.gpt_extraction import extract_metadata_with_gpt
            
            result = extract_metadata_with_gpt(
                prompt,
                model=config.get("gpt_extraction", {}).get("model", "gpt-4o-mini") if config else "gpt-4o-mini",
                temperature=0.3,
                api_key=config.get("gpt_extraction", {}).get("api_key") if config else None,
                config=config
            )
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫
            references = []
            if isinstance(result, dict) and "references" in result:
                references = result["references"]
            elif isinstance(result, list):
                references = result
            else:
                # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–∑ —Ç–µ–∫—Å—Ç–∞ –æ—Ç–≤–µ—Ç–∞
                response_text = str(result)
                # –ò—â–µ–º JSON –≤ –æ—Ç–≤–µ—Ç–µ
                import re
                json_match = re.search(r'\{.*"references".*\}', response_text, re.DOTALL)
                if json_match:
                    try:
                        parsed = json.loads(json_match.group(0))
                        references = parsed.get("references", [])
                    except:
                        pass
                
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ JSON, —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Å—Ç—Ä–æ–∫–∞–º
                if not references:
                    references = [line.strip() for line in response_text.split("\n") if line.strip() and not line.strip().startswith("{") and not line.strip().startswith("}")]
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤ —Å—Ç—Ä–æ–∫—É —Å –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏
            normalized_text = "\n".join(references)
            
            return jsonify(success=True, text=normalized_text, count=len(references))
            
        except Exception as e:
            import traceback
            error_details = traceback.format_exc()
            return jsonify(success=False, error=str(e), details=error_details), 500
    

    @app.route("/markup/<path:json_filename>/save", methods=["POST"])
    def save_metadata(json_filename: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –æ–±—Ä–∞—Ç–Ω–æ –≤ JSON —Ñ–∞–π–ª."""
        if not JSON_METADATA_AVAILABLE:
            return jsonify(success=False, error="–ú–æ–¥—É–ª—å json_metadata –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"), 500
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø—É—Ç—å –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–ø–∞—Å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        if ".." in json_filename or json_filename.startswith("/") or json_filename.startswith("\\"):
            abort(404)
        
        json_path = json_input_dir / json_filename
        
        if not json_path.exists() or not json_path.is_file():
            abort(404)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ json_input_dir
        try:
            json_path.resolve().relative_to(json_input_dir.resolve())
        except ValueError:
            abort(404)
        
        try:
            payload = request.get_json(force=True, silent=False)
            if not isinstance(payload, dict):
                return jsonify(success=False, error="–û–∂–∏–¥–∞–ª—Å—è JSON-–æ–±—ä–µ–∫—Ç."), 400
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π JSON
            existing_json = load_json_metadata(json_path)
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ —Ñ–æ—Ä–º—ã –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É JSON –∏ –æ–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π JSON
            updated_json = form_data_to_json_structure(payload, existing_json)
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥, —á—Ç–æ —Ñ–∞–π–ª –±—ã–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω —á–µ—Ä–µ–∑ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
            updated_json["_processed_via_web"] = True
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π JSON –æ–±—Ä–∞—Ç–Ω–æ –≤ –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –≤ json_input
            save_json_metadata(updated_json, json_path)
            
            return jsonify(success=True, filename=str(json_path))
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}"
            print(error_msg)
            return jsonify(success=False, error=error_msg), 500
    

