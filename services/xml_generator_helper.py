#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –º–æ–¥—É–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ XML —Ñ–∞–π–ª–æ–≤ –∏–∑ JSON —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ output.
–ü–∞—Ä—Å–∏—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏ (issn_–≥–æ–¥_—Ç–æ–º_–Ω–æ–º–µ—Ä –∏–ª–∏ issn_–≥–æ–¥_–Ω–æ–º–µ—Ä) –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–∞–Ω–Ω—ã–µ
–∏–∑ data/list_of_journals.json –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∂—É—Ä–Ω–∞–ª–∞.
"""

from __future__ import annotations

import json
import re
from pathlib import Path
from typing import Any, Dict, Optional

try:
    from services.xml_generator import (
        json_to_article_xml,
        save_xml_to_file,
        create_xml_issue,
    )
    XML_GENERATOR_AVAILABLE = True
except ImportError as e:
    XML_GENERATOR_AVAILABLE = False
    print(f"‚ö† –û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å xml_generator: {e}")
    print("   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ services/xml_generator.py –¥–æ—Å—Ç—É–ø–µ–Ω –∏ –≤—Å–µ –µ–≥–æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã.")
except Exception as e:
    XML_GENERATOR_AVAILABLE = False
    print(f"‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ xml_generator: {e}")
    print("   –í–æ–∑–º–æ–∂–Ω–æ, –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –º–æ–¥—É–ª—å journal_config –∏–ª–∏ –¥—Ä—É–≥–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏.")

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ XSD
XSD_VALIDATION_AVAILABLE = False
XSD_VALIDATION_LIBRARY: Optional[str] = None

try:
    import xmlschema  # type: ignore
    XSD_VALIDATION_AVAILABLE = True
    XSD_VALIDATION_LIBRARY = "xmlschema"
except ImportError:
    try:
        from lxml import etree  # type: ignore
        XSD_VALIDATION_AVAILABLE = True
        XSD_VALIDATION_LIBRARY = "lxml"
    except ImportError:
        XSD_VALIDATION_AVAILABLE = False
        XSD_VALIDATION_LIBRARY = None


def validate_xml_against_schema(xml_file: Path, schema_file: Optional[Path] = None) -> tuple[bool, list[str]]:
    """
    –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç XML —Ñ–∞–π–ª –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ XSD —Å—Ö–µ–º–µ.
    
    Args:
        xml_file: –ü—É—Ç—å –∫ XML —Ñ–∞–π–ª—É –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        schema_file: –ü—É—Ç—å –∫ XSD —Å—Ö–µ–º–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: data/xml_schema.xsd –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞)
        
    Returns:
        –ö–æ—Ä—Ç–µ–∂ (–≤–∞–ª–∏–¥–µ–Ω –ª–∏ —Ñ–∞–π–ª, —Å–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫)
    """
    errors: list[str] = []
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ —Å—Ö–µ–º–µ
    if schema_file is None:
        script_dir = Path(__file__).parent.resolve()
        schema_file = script_dir / "data/xml_schema.xsd"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
    if not xml_file.exists():
        errors.append(f"XML —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {xml_file}")
        return False, errors
    
    if not schema_file.exists():
        errors.append(f"XSD —Å—Ö–µ–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {schema_file}")
        return False, errors
    
    # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å xmlschema (–ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ)
    if XSD_VALIDATION_AVAILABLE and XSD_VALIDATION_LIBRARY != "lxml":
        try:
            import xmlschema
            schema = xmlschema.XMLSchema(str(schema_file))
            try:
                schema.validate(str(xml_file))
                return True, []
            except xmlschema.XMLSchemaValidationError as e:
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–∞—Ö
                try:
                    for error in schema.iter_errors(str(xml_file)):
                        error_str = str(error)
                        # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –¥–ª—è –ø—É—Å—Ç–æ–≥–æ volume (—ç—Ç–æ –¥–æ–ø—É—Å—Ç–∏–º–æ)
                        if "volume" in error_str and ("not a valid value" in error_str or "unsignedInt" in error_str):
                            continue
                        # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –¥–ª—è –ø—É—Å—Ç–æ–≥–æ references (—ç—Ç–æ –¥–æ–ø—É—Å—Ç–∏–º–æ)
                        if "references" in error_str and ("Missing child element" in error_str or "Expected is ( reference )" in error_str):
                            continue
                        # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –¥–ª—è –ø—É—Å—Ç–æ–≥–æ authorCodes (—ç—Ç–æ –¥–æ–ø—É—Å—Ç–∏–º–æ)
                        if "authorCodes" in error_str and "Missing child element" in error_str:
                            continue
                        errors.append(f"  - {error}")
                except Exception:
                    pass
                # –ï—Å–ª–∏ –≤—Å–µ –æ—à–∏–±–∫–∏ –±—ã–ª–∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã, —Å—á–∏—Ç–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é —É—Å–ø–µ—à–Ω–æ–π
                if not errors:
                    return True, []
                return False, errors
            except Exception as e:
                errors.append(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
                return False, errors
        except ImportError:
            pass
    
    # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å lxml
    if XSD_VALIDATION_AVAILABLE and XSD_VALIDATION_LIBRARY == "lxml":
        try:
            from lxml import etree
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ö–µ–º—É
            try:
                schema_doc = etree.parse(str(schema_file))
                schema = etree.XMLSchema(schema_doc)
            except Exception as e:
                errors.append(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ XSD —Å—Ö–µ–º—ã: {e}")
                return False, errors
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –≤–∞–ª–∏–¥–∏—Ä—É–µ–º XML
            try:
                xml_doc = etree.parse(str(xml_file))
                schema.assertValid(xml_doc)
                return True, []
            except etree.DocumentInvalid as e:
                # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –æ—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏, –∏—Å–∫–ª—é—á–∞—è –¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–ª—É—á–∞–∏
                for error in schema.error_log:
                    error_msg = error.message
                    # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –¥–ª—è –ø—É—Å—Ç–æ–≥–æ volume (—ç—Ç–æ –¥–æ–ø—É—Å—Ç–∏–º–æ)
                    if "volume" in error_msg and ("not a valid value" in error_msg or "unsignedInt" in error_msg):
                        continue
                    # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –¥–ª—è –ø—É—Å—Ç–æ–≥–æ references (—ç—Ç–æ –¥–æ–ø—É—Å—Ç–∏–º–æ)
                    if "references" in error_msg and ("Missing child element" in error_msg or "Expected is ( reference )" in error_msg):
                        continue
                    # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –¥–ª—è –ø—É—Å—Ç–æ–≥–æ authorCodes (—ç—Ç–æ –¥–æ–ø—É—Å—Ç–∏–º–æ)
                    if "authorCodes" in error_msg and "Missing child element" in error_msg:
                        continue
                    errors.append(f"–°—Ç—Ä–æ–∫–∞ {error.line}, –∫–æ–ª–æ–Ω–∫–∞ {error.column}: {error.message}")
                # –ï—Å–ª–∏ –≤—Å–µ –æ—à–∏–±–∫–∏ –±—ã–ª–∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã, —Å—á–∏—Ç–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é —É—Å–ø–µ—à–Ω–æ–π
                if not errors:
                    return True, []
                return False, errors
            except Exception as e:
                errors.append(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ XML: {e}")
                return False, errors
        except ImportError:
            pass
    
    # –ï—Å–ª–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é –ø—Ä–æ–≤–µ—Ä–∫—É —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
    if not XSD_VALIDATION_AVAILABLE:
        errors.append("‚ö† –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ XSD –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã (xmlschema –∏–ª–∏ lxml)")
        errors.append("   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –æ–¥–Ω—É –∏–∑ –Ω–∏—Ö: pip install xmlschema –∏–ª–∏ pip install lxml")
        errors.append("   –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –±–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã XML...")
        
        try:
            import xml.etree.ElementTree as ET
            tree = ET.parse(xml_file)
            root = tree.getroot()
            
            # –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            if root.tag != "journal":
                errors.append("–ö–æ—Ä–Ω–µ–≤–æ–π —ç–ª–µ–º–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 'journal'")
                return False, errors
            
            required_elements = ["titleid", "journalInfo", "issue"]
            for elem_name in required_elements:
                if root.find(elem_name) is None:
                    errors.append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç: {elem_name}")
            
            if errors:
                return False, errors
            
            # –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ
            return True, []
        except ET.ParseError as e:
            errors.append(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ XML: {e}")
            return False, errors
        except Exception as e:
            errors.append(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ XML: {e}")
            return False, errors
    
    return False, errors


def parse_pages_range(pages_str: str) -> Optional[tuple[int, int]]:
    """
    –ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫—É —Å –¥–∏–∞–ø–∞–∑–æ–Ω–æ–º —Å—Ç—Ä–∞–Ω–∏—Ü –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É.
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:
    - "4-16" -> (4, 16)
    - "4‚Äì16" (—Ç–∏—Ä–µ) -> (4, 16)
    - "4‚Äî16" (–¥–ª–∏–Ω–Ω–æ–µ —Ç–∏—Ä–µ) -> (4, 16)
    - "4" -> (4, 4)
    - "4-16, 20-25" -> –±–µ—Ä–µ—Ç—Å—è –ø–µ—Ä–≤—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω (4, 16)
    
    Args:
        pages_str: –°—Ç—Ä–æ–∫–∞ —Å –¥–∏–∞–ø–∞–∑–æ–Ω–æ–º —Å—Ç—Ä–∞–Ω–∏—Ü
        
    Returns:
        –ö–æ—Ä—Ç–µ–∂ (min_page, max_page) –∏–ª–∏ None, –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
    """
    if not pages_str or not pages_str.strip():
        return None
    
    pages_str = pages_str.strip()
    
    # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã
    pages_str = pages_str.replace(" ", "")
    
    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏: -, ‚Äì, ‚Äî, ,
    for separator in ["-", "‚Äì", "‚Äî", ","]:
        if separator in pages_str:
            parts = pages_str.split(separator, 1)
            if len(parts) == 2:
                try:
                    start = int(parts[0])
                    # –î–ª—è –≤—Ç–æ—Ä–æ–≥–æ —á–∏—Å–ª–∞ –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é —á–∞—Å—Ç—å (–¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è)
                    end_str = parts[1].split(",")[0].split("-")[0].split("‚Äì")[0].split("‚Äî")[0]
                    end = int(end_str)
                    return (min(start, end), max(start, end))
                except ValueError:
                    continue
    
    # –ï—Å–ª–∏ —ç—Ç–æ –æ–¥–Ω–æ —á–∏—Å–ª–æ
    try:
        page_num = int(pages_str.split(",")[0].split("-")[0].split("‚Äì")[0].split("‚Äî")[0])
        return (page_num, page_num)
    except ValueError:
        return None


def analyze_issue_pages(json_files: list[Path]) -> Optional[str]:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π –≤ JSON —Ñ–∞–π–ª–∞—Ö –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –¥–∏–∞–ø–∞–∑–æ–Ω —Å—Ç—Ä–∞–Ω–∏—Ü –≤—ã–ø—É—Å–∫–∞.
    
    Args:
        json_files: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ JSON —Ñ–∞–π–ª–∞–º —Å—Ç–∞—Ç–µ–π
        
    Returns:
        –°—Ç—Ä–æ–∫–∞ —Å –¥–∏–∞–ø–∞–∑–æ–Ω–æ–º —Å—Ç—Ä–∞–Ω–∏—Ü –≤ —Ñ–æ—Ä–º–∞—Ç–µ "min-max" –∏–ª–∏ None, –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å
    """
    if not json_files:
        return None
    
    min_page = None
    max_page = None
    
    for json_file in json_files:
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            pages_str = data.get("pages", "")
            if not pages_str:
                continue
            
            pages_range = parse_pages_range(pages_str)
            if pages_range:
                article_min, article_max = pages_range
                
                if min_page is None or article_min < min_page:
                    min_page = article_min
                if max_page is None or article_max > max_page:
                    max_page = article_max
        except Exception as e:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª—ã —Å –æ—à–∏–±–∫–∞–º–∏
            print(f"   ‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Å—Ç—Ä–∞–Ω–∏—Ü –≤ {json_file.name}: {e}")
            continue
    
    if min_page is not None and max_page is not None:
        if min_page == max_page:
            return str(min_page)
        else:
            return f"{min_page}-{max_page}"
    
    return None


def parse_folder_name(folder_name: str) -> Optional[Dict[str, Any]]:
    """
    –ü–∞—Ä—Å–∏—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏ —Ñ–æ—Ä–º–∞—Ç–∞ issn_–≥–æ–¥_—Ç–æ–º_–Ω–æ–º–µ—Ä –∏–ª–∏ issn_–≥–æ–¥_–Ω–æ–º–µ—Ä.
    
    Args:
        folder_name: –ù–∞–∑–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "2619-1601_2024_6" –∏–ª–∏ "2619-1601_2024_10_6")
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –ø–æ–ª—è–º–∏: issn, year, volume (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ), number
        –∏–ª–∏ None, –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
    """
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞:
    # issn_–≥–æ–¥_–Ω–æ–º–µ—Ä (–Ω–∞–ø—Ä–∏–º–µ—Ä: 2619-1601_2024_6 –∏–ª–∏ 0869-544X_2025_6)
    # issn_–≥–æ–¥_—Ç–æ–º_–Ω–æ–º–µ—Ä (–Ω–∞–ø—Ä–∏–º–µ—Ä: 2619-1601_2024_10_6)
    # ISSN –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–∞—Ö: XXXX-XXXX, XXXX-XXX[X], XXXX-XXXX[X]
    # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º: 4 —Ü–∏—Ñ—Ä—ã-3 —Ü–∏—Ñ—Ä—ãX, 4 —Ü–∏—Ñ—Ä—ã-4 —Ü–∏—Ñ—Ä—ã, 4 —Ü–∏—Ñ—Ä—ã-4 —Ü–∏—Ñ—Ä—ãX
    # Normalize Unicode dashes to ASCII hyphen for ISSN parsing.
    folder_name = (
        folder_name
        .replace("\u2013", "-")
        .replace("\u2014", "-")
        .replace("\u2212", "-")
    )

    pattern1 = r'^([0-9]{4}-[0-9]{3}[X]|[0-9]{4}-[0-9]{4}[X]?)_(\d{4})_(\d+)$'  # issn_–≥–æ–¥_–Ω–æ–º–µ—Ä
    pattern2 = r'^([0-9]{4}-[0-9]{3}[X]|[0-9]{4}-[0-9]{4}[X]?)_(\d{4})_(\d+)_(\d+)$'  # issn_–≥–æ–¥_—Ç–æ–º_–Ω–æ–º–µ—Ä

    match1 = re.match(pattern1, folder_name)
    if match1:
        return {
            "issn": match1.group(1),
            "year": match1.group(2),
            "volume": None,
            "number": match1.group(3),
        }
    
    match2 = re.match(pattern2, folder_name)
    if match2:
        return {
            "issn": match2.group(1),
            "year": match2.group(2),
            "volume": match2.group(3),
            "number": match2.group(4),
        }
    
    return None


def load_journal_from_list(issn: str, list_of_journals_path: Path) -> Optional[Dict[str, Any]]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∂—É—Ä–Ω–∞–ª–∞ –∏–∑ data/list_of_journals.json –ø–æ ISSN.
    
    Args:
        issn: ISSN –∂—É—Ä–Ω–∞–ª–∞
        list_of_journals_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É data/list_of_journals.json
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –∂—É—Ä–Ω–∞–ª–∞ (ISSN –∏ Title) –∏–ª–∏ None, –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω
    """
    if not list_of_journals_path.exists():
        return None
    
    try:
        with open(list_of_journals_path, 'r', encoding='utf-8') as f:
            journals = json.load(f)
        
        # –ò—â–µ–º –∂—É—Ä–Ω–∞–ª –ø–æ ISSN
        for journal in journals:
            if journal.get("ISSN", "").upper() == issn.upper():
                return journal
        
        return None
    except Exception as e:
        print(f"‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ data/list_of_journals.json: {e}")
        return None


def create_config_from_folder_and_journal(
    folder_name: str,
    list_of_journals_path: Path,
    titleid: Optional[int] = None,
) -> Optional[Dict[str, Any]]:
    """
    –°–æ–∑–¥–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∂—É—Ä–Ω–∞–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–∑–≤–∞–Ω–∏—è –ø–∞–ø–∫–∏ –∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ data/list_of_journals.json.
    
    Args:
        folder_name: –ù–∞–∑–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "2619-1601_2024_6")
        list_of_journals_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É data/list_of_journals.json
        titleid: ID –∂—É—Ä–Ω–∞–ª–∞ –≤ elibrary (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –∂—É—Ä–Ω–∞–ª–∞ –¥–ª—è xml_generator –∏–ª–∏ None
    """
    # –ü–∞—Ä—Å–∏–º –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏
    issue_info = parse_folder_name(folder_name)
    if not issue_info:
        print(f"‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏: {folder_name}")
        print("üí° –û–∂–∏–¥–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: ISSN_–ì–û–î_–ù–û–ú–ï–† –∏–ª–∏ ISSN_–ì–û–î_–¢–û–ú_–ù–û–ú–ï–†")
        return None
    
    issn = issue_info["issn"]
    year = issue_info["year"]
    volume = issue_info.get("volume")
    number = issue_info.get("number")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∂—É—Ä–Ω–∞–ª–∞
    journal_data = load_journal_from_list(issn, list_of_journals_path)
    if not journal_data:
        print(f"‚ö† –ñ—É—Ä–Ω–∞–ª —Å ISSN {issn} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ data/list_of_journals.json")
        return None
    
    journal_title = journal_data.get("Title", "")
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config: Dict[str, Any] = {
        "titleid": titleid if titleid else 0,  # –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º 0 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        "issn": issn,
        "journal_titles": {
            "ru": journal_title,
            "en": journal_title,  # –ï—Å–ª–∏ –µ—Å—Ç—å –æ—Ç–¥–µ–ª—å–Ω–æ–µ –∞–Ω–≥–ª–∏–π—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ, –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å
        },
        "issue": {
            "year": year,
            "number": number,
            "pages": "",  # –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ –¥–ª—è xml_generator, –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        },
    }
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–º, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
    if volume:
        config["issue"]["volume"] = volume
    else:
        # –ï—Å–ª–∏ —Ç–æ–º–∞ –Ω–µ—Ç, –¥–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É (xml_generator —Ç—Ä–µ–±—É–µ—Ç –ª–∏–±–æ volume, –ª–∏–±–æ number)
        config["issue"]["volume"] = ""
    
    return config


def generate_xml_for_output_folder(
    json_input_dir: Path,
    xml_output_dir: Path,
    list_of_journals_path: Path,
    folder_name: str,
) -> Optional[Path]:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç XML —Ñ–∞–π–ª –¥–ª—è –≤—ã–ø—É—Å–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ JSON —Ñ–∞–π–ª–æ–≤ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–æ–¥–ø–∞–ø–∫–µ json_input.
    
    Args:
        json_input_dir: –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è json_input (–Ω–∞–ø—Ä–∏–º–µ—Ä, Path("json_input"))
        xml_output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è XML —Ñ–∞–π–ª–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, Path("xml_output"))
        list_of_journals_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É data/list_of_journals.json
        folder_name: –ù–∞–∑–≤–∞–Ω–∏–µ –ø–æ–¥–ø–∞–ø–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "2619-1601_2024_6")
        
    Returns:
        –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É XML —Ñ–∞–π–ª—É –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
    """
    if not XML_GENERATOR_AVAILABLE:
        print("‚ùå –û—à–∏–±–∫–∞: xml_generator –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        return None


def generate_xml_for_archive_dir(
    archive_dir: Path,
    list_of_journals_path: Path,
) -> Optional[Path]:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç XML —Ñ–∞–π–ª –¥–ª—è –≤—ã–ø—É—Å–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ JSON —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ –∞—Ä—Ö–∏–≤–∞.

    –°—Ç—Ä—É–∫—Ç—É—Ä–∞:
      input_files/<–∞—Ä—Ö–∏–≤>/json/*.json
      input_files/<–∞—Ä—Ö–∏–≤>/xml/<–∞—Ä—Ö–∏–≤>.xml
    """
    if not XML_GENERATOR_AVAILABLE:
        print("‚ùå –û—à–∏–±–∫–∞: xml_generator –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        return None

    if not archive_dir.exists() or not archive_dir.is_dir():
        print(f"‚ö† –ü–∞–ø–∫–∞ –∞—Ä—Ö–∏–≤–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {archive_dir}")
        return None

    json_folder_path = archive_dir / "json"
    if not json_folder_path.exists() or not json_folder_path.is_dir():
        print(f"‚ö† –ü–∞–ø–∫–∞ —Å JSON –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {json_folder_path}")
        return None

    folder_name = archive_dir.name
    json_files = list(json_folder_path.glob("*.json"))
    if not json_files:
        print(f"‚ö† –í –ø–∞–ø–∫–µ {json_folder_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ JSON —Ñ–∞–π–ª–æ–≤")
        return None

    print(f"üìÑ –ù–∞–π–¥–µ–Ω–æ {len(json_files)} JSON —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ {json_folder_path}")

    issue_pages = analyze_issue_pages(json_files)
    if issue_pages:
        print(f"üìÑ –î–∏–∞–ø–∞–∑–æ–Ω —Å—Ç—Ä–∞–Ω–∏—Ü –≤—ã–ø—É—Å–∫–∞: {issue_pages}")
    else:
        print("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω —Å—Ç—Ä–∞–Ω–∏—Ü –≤—ã–ø—É—Å–∫–∞")

    config = create_config_from_folder_and_journal(folder_name, list_of_journals_path)
    if not config:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è –ø–∞–ø–∫–∏ {folder_name}")
        return None

    if issue_pages:
        config["issue"]["pages"] = issue_pages

    try:
        tree = create_xml_issue(config)
        root = tree.getroot()

        issue_elem = root.find("issue")
        if issue_elem is None:
            print("‚ùå –û—à–∏–±–∫–∞: –Ω–µ –Ω–∞–π–¥–µ–Ω —ç–ª–µ–º–µ–Ω—Ç issue –≤ XML —Å—Ç—Ä—É–∫—Ç—É—Ä–µ")
            return None

        articles_elem = issue_elem.find("articles")
        if articles_elem is None:
            print("‚ùå –û—à–∏–±–∫–∞: –Ω–µ –Ω–∞–π–¥–µ–Ω —ç–ª–µ–º–µ–Ω—Ç articles –≤ XML —Å—Ç—Ä—É–∫—Ç—É—Ä–µ")
            return None

        for json_file in sorted(json_files):
            try:
                article_elem = json_to_article_xml(json_file)
                articles_elem.append(article_elem)
                print(f"   ‚úì –î–æ–±–∞–≤–ª–µ–Ω–∞ —Å—Ç–∞—Ç—å—è: {json_file.name}")
            except Exception as e:
                print(f"   ‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {json_file.name}: {e}")

        xml_folder_path = archive_dir / "xml"
        xml_folder_path.mkdir(parents=True, exist_ok=True)
        xml_filename = f"{folder_name}.xml"
        xml_path = save_xml_to_file(tree, xml_filename, str(xml_folder_path))

        print(f"‚úÖ XML —Ñ–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω: {xml_path}")

        print("\nüîç –í–∞–ª–∏–¥–∞—Ü–∏—è XML —Ñ–∞–π–ª–∞...")
        is_valid, errors = validate_xml_against_schema(xml_path)
        if is_valid:
            print("‚úÖ XML —Ñ–∞–π–ª –ø—Ä–æ—à–µ–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é —É—Å–ø–µ—à–Ω–æ!")
        else:
            print("‚ùå XML —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:")
            print("-" * 60)
            for i, error in enumerate(errors, 1):
                print(f"   {i}. {error}")
            print("-" * 60)
            print(f"   –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –æ—à–∏–±–æ–∫: {len(errors)}")
        return xml_path
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ XML: {e}")
        return None
    
    # –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å JSON —Ñ–∞–π–ª–∞–º–∏
    json_folder_path = json_input_dir / folder_name
    
    if not json_folder_path.exists() or not json_folder_path.is_dir():
        print(f"‚ö† –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {json_folder_path}")
        return None
    
    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ JSON —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ
    json_files = list(json_folder_path.glob("*.json"))
    
    if not json_files:
        print(f"‚ö† –í –ø–∞–ø–∫–µ {folder_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ JSON —Ñ–∞–π–ª–æ–≤")
        return None
    
    print(f"üìÑ –ù–∞–π–¥–µ–Ω–æ {len(json_files)} JSON —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ {folder_name}")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å—Ç–∞—Ç–µ–π –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–∏–∞–ø–∞–∑–æ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü –≤—ã–ø—É—Å–∫–∞
    issue_pages = analyze_issue_pages(json_files)
    if issue_pages:
        print(f"üìÑ –î–∏–∞–ø–∞–∑–æ–Ω —Å—Ç—Ä–∞–Ω–∏—Ü –≤—ã–ø—É—Å–∫–∞: {issue_pages}")
    else:
        print(f"‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω —Å—Ç—Ä–∞–Ω–∏—Ü –≤—ã–ø—É—Å–∫–∞")
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∂—É—Ä–Ω–∞–ª–∞
    config = create_config_from_folder_and_journal(folder_name, list_of_journals_path)
    if not config:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è –ø–∞–ø–∫–∏ {folder_name}")
        return None
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω —Å—Ç—Ä–∞–Ω–∏—Ü –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏, –µ—Å–ª–∏ –æ–Ω –±—ã–ª –æ–ø—Ä–µ–¥–µ–ª–µ–Ω
    if issue_pages:
        config["issue"]["pages"] = issue_pages
    
    print(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∞:")
    print(f"   ISSN: {config.get('issn')}")
    print(f"   –ñ—É—Ä–Ω–∞–ª: {config.get('journal_titles', {}).get('ru', '–ù–ï –ó–ê–î–ê–ù')}")
    print(f"   –ì–æ–¥: {config.get('issue', {}).get('year')}")
    if config.get('issue', {}).get('volume'):
        print(f"   –¢–æ–º: {config.get('issue', {}).get('volume')}")
    print(f"   –ù–æ–º–µ—Ä: {config.get('issue', {}).get('number')}")
    if config.get('issue', {}).get('pages'):
        print(f"   –°—Ç—Ä–∞–Ω–∏—Ü—ã: {config.get('issue', {}).get('pages')}")
    
    # –°–æ–∑–¥–∞–µ–º XML —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    try:
        # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≤—ã–ø—É—Å–∫–∞
        tree = create_xml_issue(config)
        root = tree.getroot()
        
        # –ù–∞—Ö–æ–¥–∏–º —ç–ª–µ–º–µ–Ω—Ç articles
        issue_elem = root.find("issue")
        if issue_elem is None:
            print("‚ùå –û—à–∏–±–∫–∞: –Ω–µ –Ω–∞–π–¥–µ–Ω —ç–ª–µ–º–µ–Ω—Ç issue –≤ XML —Å—Ç—Ä—É–∫—Ç—É—Ä–µ")
            return None
        
        articles_elem = issue_elem.find("articles")
        if articles_elem is None:
            print("‚ùå –û—à–∏–±–∫–∞: –Ω–µ –Ω–∞–π–¥–µ–Ω —ç–ª–µ–º–µ–Ω—Ç articles –≤ XML —Å—Ç—Ä—É–∫—Ç—É—Ä–µ")
            return None
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç—å–∏ –∏–∑ JSON —Ñ–∞–π–ª–æ–≤
        for json_file in sorted(json_files):
            try:
                article_elem = json_to_article_xml(json_file)
                articles_elem.append(article_elem)
                print(f"   ‚úì –î–æ–±–∞–≤–ª–µ–Ω–∞ —Å—Ç–∞—Ç—å—è: {json_file.name}")
            except Exception as e:
                print(f"   ‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {json_file.name}: {e}")
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è XML –≤ xml_output —Å —Ç–µ–º –∂–µ –Ω–∞–∑–≤–∞–Ω–∏–µ–º
        xml_folder_path = xml_output_dir / folder_name
        xml_folder_path.mkdir(parents=True, exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º XML —Ñ–∞–π–ª
        xml_filename = f"{folder_name}.xml"
        xml_path = save_xml_to_file(tree, xml_filename, str(xml_folder_path))
        
        print(f"‚úÖ XML —Ñ–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω: {xml_path}")
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è XML —Ñ–∞–π–ª–∞
        print("\nüîç –í–∞–ª–∏–¥–∞—Ü–∏—è XML —Ñ–∞–π–ª–∞...")
        is_valid, errors = validate_xml_against_schema(xml_path)
        
        if is_valid:
            print("‚úÖ XML —Ñ–∞–π–ª –ø—Ä–æ—à–µ–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é —É—Å–ø–µ—à–Ω–æ!")
            print("   –í—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã, —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Å—Ö–µ–º–µ.")
        else:
            print("‚ùå XML —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:")
            print("-" * 60)
            for i, error in enumerate(errors, 1):
                print(f"   {i}. {error}")
            print("-" * 60)
            print(f"   –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –æ—à–∏–±–æ–∫: {len(errors)}")
            print("‚ö† –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø—Ä–∞–≤–∏—Ç—å –æ—à–∏–±–∫–∏ –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ñ–∞–π–ª–∞.")
        
        return xml_path
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ XML: {e}")
        return None


def generate_xml_for_all_folders(
    json_input_dir: Path,
    xml_output_dir: Path,
    list_of_journals_path: Path,
) -> list[Path]:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç XML —Ñ–∞–π–ª—ã –¥–ª—è –≤—Å–µ—Ö –ø–æ–¥–ø–∞–ø–æ–∫ –≤ json_input_dir.
    
    Args:
        json_input_dir: –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è json_input
        xml_output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è XML —Ñ–∞–π–ª–æ–≤
        list_of_journals_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É data/list_of_journals.json
        
    Returns:
        –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Å–æ–∑–¥–∞–Ω–Ω—ã–º XML —Ñ–∞–π–ª–∞–º
    """
    if not json_input_dir.exists() or not json_input_dir.is_dir():
        print(f"‚ö† –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è json_input –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {json_input_dir}")
        return []
    
    created_xml_files = []
    
    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –ø–æ–¥–ø–∞–ø–∫–∏ –≤ json_input_dir
    for folder_path in json_input_dir.iterdir():
        if not folder_path.is_dir():
            continue
        
        folder_name = folder_path.name
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–∞–ø–∫–∏, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
        if folder_name.startswith('.'):
            continue
        
        print(f"\n{'=' * 80}")
        print(f"üìÅ –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–ø–∫–∏: {folder_name}")
        print(f"{'=' * 80}")
        
        xml_path = generate_xml_for_output_folder(
            json_input_dir,
            xml_output_dir,
            list_of_journals_path,
            folder_name,
        )
        
        if xml_path:
            created_xml_files.append(xml_path)
    
    return created_xml_files


# ----------------------------
# CLI / –ó–∞–ø—É—Å–∫
# ----------------------------

def main() -> int:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ XML —Ñ–∞–π–ª–æ–≤ –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏.
    
    Returns:
        –ö–æ–¥ –≤–æ–∑–≤—Ä–∞—Ç–∞ (0 - —É—Å–ø–µ—Ö, 1 - –æ—à–∏–±–∫–∞)
    """
    import argparse
    
    parser = argparse.ArgumentParser(
        description="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è XML —Ñ–∞–π–ª–æ–≤ –¥–ª—è –≤—ã–ø—É—Å–∫–æ–≤ –∂—É—Ä–Ω–∞–ª–æ–≤ –∏–∑ JSON —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ output"
    )
    parser.add_argument(
        "--output-dir",
        default=None,
        help="–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ output —Å JSON —Ñ–∞–π–ª–∞–º–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: output)"
    )
    parser.add_argument(
        "--xml-output-dir",
        default=None,
        help="–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è XML —Ñ–∞–π–ª–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: xml_output)"
    )
    parser.add_argument(
        "--list-of-journals",
        default=None,
        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É data/list_of_journals.json (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: data/list_of_journals.json)"
    )
    parser.add_argument(
        "--folder",
        default=None,
        help="–û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ —É–∫–∞–∑–∞–Ω–Ω—É—é –ø–æ–¥–ø–∞–ø–∫—É (–Ω–∞–ø—Ä–∏–º–µ—Ä: 2619-1601_2024_6). –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –≤—Å–µ –ø–æ–¥–ø–∞–ø–∫–∏"
    )
    
    args = parser.parse_args()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏
    script_dir = Path(__file__).parent.resolve()
    
    if args.output_dir:
        json_input_dir = Path(args.output_dir)
        if not json_input_dir.is_absolute():
            json_input_dir = script_dir / json_input_dir
    else:
        json_input_dir = script_dir / "json_input"
    
    if args.xml_output_dir:
        xml_output_dir = Path(args.xml_output_dir)
        if not xml_output_dir.is_absolute():
            xml_output_dir = script_dir / xml_output_dir
    else:
        xml_output_dir = script_dir / "xml_output"
    
    if args.list_of_journals:
        list_of_journals_path = Path(args.list_of_journals)
        if not list_of_journals_path.is_absolute():
            list_of_journals_path = script_dir / list_of_journals_path
    else:
        list_of_journals_path = script_dir / "data/list_of_journals.json"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥—É–ª–µ–π
    if not XML_GENERATOR_AVAILABLE:
        print("‚ùå –û—à–∏–±–∫–∞: xml_generator –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        print("   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ services/xml_generator.py –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ç–æ–π –∂–µ –ø–∞–ø–∫–µ")
        return 1
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞ data/list_of_journals.json
    if not list_of_journals_path.exists():
        print(f"‚ùå –û—à–∏–±–∫–∞: —Ñ–∞–π–ª data/list_of_journals.json –Ω–µ –Ω–∞–π–¥–µ–Ω: {list_of_journals_path}")
        return 1
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–∞–ø–∫–∏ json_input
    if not json_input_dir.exists() or not json_input_dir.is_dir():
        print(f"‚ö† –ü–∞–ø–∫–∞ json_input –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {json_input_dir}")
        print("   –°–æ–∑–¥–∞–π—Ç–µ –ø–∞–ø–∫—É json_input –∏ –ø–æ–º–µ—Å—Ç–∏—Ç–µ —Ç—É–¥–∞ JSON —Ñ–∞–π–ª—ã –≤ –ø–æ–¥–ø–∞–ø–∫–∞—Ö")
        return 1
    
    print("\n" + "=" * 80)
    print("üìÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è XML —Ñ–∞–π–ª–æ–≤ –¥–ª—è –≤—ã–ø—É—Å–∫–æ–≤ –∂—É—Ä–Ω–∞–ª–æ–≤")
    print("=" * 80)
    print(f"üìÅ –ü–∞–ø–∫–∞ —Å JSON —Ñ–∞–π–ª–∞–º–∏: {json_input_dir}")
    print(f"üìÅ –ü–∞–ø–∫–∞ –¥–ª—è XML —Ñ–∞–π–ª–æ–≤: {xml_output_dir}")
    print(f"üìã –§–∞–π–ª —Å–æ —Å–ø–∏—Å–∫–æ–º –∂—É—Ä–Ω–∞–ª–æ–≤: {list_of_journals_path}")
    print("=" * 80 + "\n")
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è XML —Ñ–∞–π–ª–æ–≤, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    xml_output_dir.mkdir(parents=True, exist_ok=True)
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º XML —Ñ–∞–π–ª—ã
    if args.folder:
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —É–∫–∞–∑–∞–Ω–Ω—É—é –ø–æ–¥–ø–∞–ø–∫—É
        folder_name = args.folder
        print(f"üìÅ –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–ø–∫–∏: {folder_name}\n")
        xml_path = generate_xml_for_output_folder(
            json_input_dir,
            xml_output_dir,
            list_of_journals_path,
            folder_name,
        )
        if xml_path:
            print(f"\n‚úÖ XML —Ñ–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω: {xml_path}")
            return 0
        else:
            print(f"\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å XML —Ñ–∞–π–ª –¥–ª—è –ø–∞–ø–∫–∏ {folder_name}")
            return 1
    else:
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –ø–æ–¥–ø–∞–ø–∫–∏
        created_xml_files = generate_xml_for_all_folders(
            json_input_dir,
            xml_output_dir,
            list_of_journals_path,
        )
        
        if created_xml_files:
            print(f"\n‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–æ XML —Ñ–∞–π–ª–æ–≤: {len(created_xml_files)}")
            for xml_path in created_xml_files:
                print(f"   - {xml_path}")
            return 0
        else:
            print("\n‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ XML —Ñ–∞–π–ª–∞")
            print("   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ:")
            print("   1. –í –ø–∞–ø–∫–µ output –µ—Å—Ç—å –ø–æ–¥–ø–∞–ø–∫–∏ —Å JSON —Ñ–∞–π–ª–∞–º–∏")
            print("   2. JSON —Ñ–∞–π–ª—ã –∏–º–µ—é—Ç —Å—É—Ñ—Ñ–∏–∫—Å _processed.json")
            print("   3. –ù–∞–∑–≤–∞–Ω–∏—è –ø–æ–¥–ø–∞–ø–æ–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Ñ–æ—Ä–º–∞—Ç—É: issn_–≥–æ–¥_–Ω–æ–º–µ—Ä –∏–ª–∏ issn_–≥–æ–¥_—Ç–æ–º_–Ω–æ–º–µ—Ä")
            print("   4. –ñ—É—Ä–Ω–∞–ª—ã —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º–∏ ISSN –Ω–∞–π–¥–µ–Ω—ã –≤ data/list_of_journals.json")
            return 1


if __name__ == "__main__":
    import sys
    sys.exit(main())

